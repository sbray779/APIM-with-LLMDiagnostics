# Azure APIM with OpenAI Backend - Terraform

This Terraform repository deploys Azure API Management (APIM) with Azure OpenAI backend services, including comprehensive LLM logging and diagnostics capabilities using the azapi provider.

## üèóÔ∏è Architecture Overview

The deployment creates a secure, enterprise-ready infrastructure with the following components:

- **Azure OpenAI Service**: Private deployment with GPT and embedding models
- **Azure API Management**: Gateway for OpenAI APIs with advanced policies
- **Comprehensive Monitoring**: Application Insights, Log Analytics, Event Hub
- **Advanced Diagnostics**: LLM-specific logging using azapi provider
- **Network Security**: Private endpoints, VNet integration, NSGs
- **Identity Management**: Managed identities for secure service-to-service authentication

## üöÄ Quick Start

### Prerequisites

1. **Azure CLI**: Install and authenticate with your Azure subscription
   ```powershell
   # Install Azure CLI (if not already installed)
   winget install Microsoft.AzureCli
   
   # Login to Azure
   az login
   ```

2. **Terraform**: Install Terraform (>= 1.5)
   ```powershell
   # Install Terraform
   winget install Hashicorp.Terraform
   ```

3. **Azure Permissions**: Ensure you have the following permissions:
   - Contributor or Owner on the target subscription/resource group
   - Ability to create managed identities and role assignments

### Deployment Steps

1. **Clone and Configure**
   ```powershell
   # Clone the repository (or copy the files to your local directory)
   cd APIMDiag
   
   # Copy the example configuration
   Copy-Item "examples\terraform.tfvars.example" -Destination "terraform.tfvars"
   ```

2. **Customize Configuration**
   Edit `terraform.tfvars` with your specific requirements:
   ```hcl
   environment_name = "prod"
   location         = "East US"
   publisher_email  = "admin@yourcompany.com"
   publisher_name   = "Your Company"
   # ... additional configurations
   ```

3. **Initialize and Deploy**
   ```powershell
   # Initialize Terraform
   terraform init
   
   # Validate the configuration
   terraform validate
   
   # Plan the deployment
   terraform plan
   
   # Apply the configuration
   terraform apply -auto-approve
   ```

4. **Retrieve Connection Information**
   ```powershell
   # Get APIM gateway URL
   terraform output apim_gateway_url
   
   # Get subscription key (sensitive output)
   terraform output -raw subscription_key
   ```

## üìã Module Structure

```
‚îú‚îÄ‚îÄ main.tf                 # Provider configuration
‚îú‚îÄ‚îÄ resources.tf           # Main resource definitions
‚îú‚îÄ‚îÄ variables.tf           # Input variables
‚îú‚îÄ‚îÄ outputs.tf            # Output values
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ networking/       # VNet, subnets, NSGs, private DNS
‚îÇ   ‚îú‚îÄ‚îÄ openai/          # Azure OpenAI service and deployments
‚îÇ   ‚îú‚îÄ‚îÄ apim/            # API Management service and configuration
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/      # Log Analytics, App Insights, Event Hub
‚îÇ   ‚îî‚îÄ‚îÄ diagnostics/     # APIM diagnostics using azapi provider
‚îî‚îÄ‚îÄ examples/
    ‚îî‚îÄ‚îÄ terraform.tfvars.example  # Example configuration
```

## üîß Configuration Options

### Core Configuration

| Variable | Description | Default | Options |
|----------|-------------|---------|---------|
| `environment_name` | Environment identifier | `dev` | Any alphanumeric string |
| `location` | Azure region | `East US` | Any valid Azure region |
| `publisher_email` | APIM publisher email | `admin@company.com` | Valid email address |

### API Management SKUs

| SKU | Description | Use Case | Capacity |
|-----|-------------|----------|----------|
| `Developer` | Development/testing | Non-production | 1 unit |
| `Standard` | Production workloads | Standard production | 1-10 units |
| `Premium` | Enterprise features | High availability | 1-10 units |

### OpenAI Models

#### Supported GPT Models
- `gpt-35-turbo` (Default)
- `gpt-35-turbo-16k`
- `gpt-4`
- `gpt-4-32k`
- `gpt-4-turbo`
- `gpt-4o`

#### Supported Embedding Models
- `text-embedding-ada-002` (Default)
- `text-embedding-3-small`
- `text-embedding-3-large`

## üîí Security Features

### Network Security
- **Private Endpoints**: All services use private endpoints
- **VNet Integration**: APIM integrated with virtual network
- **NSG Rules**: Restrictive network security group rules
- **Private DNS**: Private DNS zones for service resolution

### Identity and Access Management
- **Managed Identities**: User-assigned identities for APIM and Function App
- **RBAC**: Role-based access control for OpenAI service
- **Key Vault**: Secure storage of secrets and API keys
- **Certificate Validation**: TLS certificate chain validation

### API Security
- **Subscription Keys**: Required for API access
- **Rate Limiting**: Built-in throttling policies
- **IP Filtering**: Optional IP address restrictions
- **Data Masking**: Sensitive headers masked in logs

## üìä Monitoring and Diagnostics

### Comprehensive Logging
The deployment includes advanced diagnostics using the azapi provider:

- **Service-Level Diagnostics**: Overall APIM service monitoring
- **API-Level Diagnostics**: OpenAI API specific logging
- **Operation-Level Diagnostics**: Individual operation tracking
  - Chat Completions (65KB request/response logging)
  - Completions (65KB request/response logging)
  - Embeddings (32KB request/response logging)

### Log Analytics Queries

Query token usage by subscription:
```kusto
ApiManagementGatewayLogs
| where OperationName in ("ChatCompletions_Create", "Completions_Create")
| extend RequestBody = parse_json(RequestBody)
| extend ResponseBody = parse_json(ResponseBody)
| extend PromptTokens = toint(ResponseBody.usage.prompt_tokens)
| extend CompletionTokens = toint(ResponseBody.usage.completion_tokens)
| extend TotalTokens = toint(ResponseBody.usage.total_tokens)
| summarize 
    TotalRequests = count(),
    TotalPromptTokens = sum(PromptTokens),
    TotalCompletionTokens = sum(CompletionTokens),
    TotalTokens = sum(TotalTokens)
by SubscriptionId, OperationName
```

### Event Hub Integration
- Real-time streaming of API requests/responses
- Integration with Azure Functions for token calculation
- Custom event processing for chargeback scenarios

## üß™ Testing the Deployment

### Test Chat Completions
```powershell
# Set variables from Terraform outputs
$gatewayUrl = terraform output -raw apim_gateway_url
$subscriptionKey = terraform output -raw subscription_key
$gptDeployment = terraform output -raw gpt_deployment_name

# Test chat completions
$headers = @{
    'Ocp-Apim-Subscription-Key' = $subscriptionKey
    'Content-Type' = 'application/json'
}

$body = @{
    messages = @(
        @{ role = "system"; content = "You are a helpful assistant." }
        @{ role = "user"; content = "Hello, how are you?" }
    )
    max_tokens = 100
    temperature = 0.7
} | ConvertTo-Json -Depth 10

$response = Invoke-RestMethod -Uri "$gatewayUrl/openai/deployments/$gptDeployment/chat/completions?api-version=2023-05-15" -Method POST -Headers $headers -Body $body

Write-Output $response.choices[0].message.content
```

### Test Embeddings
```powershell
$embeddingDeployment = terraform output -raw embedding_deployment_name

$body = @{
    input = "The quick brown fox jumps over the lazy dog"
} | ConvertTo-Json

$response = Invoke-RestMethod -Uri "$gatewayUrl/openai/deployments/$embeddingDeployment/embeddings?api-version=2023-05-15" -Method POST -Headers $headers -Body $body

Write-Output "Embedding dimension: $($response.data[0].embedding.Count)"
```

## üîß Customization

### Adding Custom Policies

To add custom APIM policies, modify the `modules/apim/main.tf` file:

```hcl
resource "azurerm_api_management_api_policy" "openai" {
  # ... existing configuration
  
  xml_content = <<XML
<policies>
    <inbound>
        <base />
        <!-- Add your custom policies here -->
        <rate-limit calls="100" renewal-period="60" />
        <quota calls="1000" renewal-period="3600" />
    </inbound>
    <!-- ... rest of policy -->
</policies>
XML
}
```

### Environment-Specific Configurations

Create environment-specific `.tfvars` files:

```
environments/
‚îú‚îÄ‚îÄ dev.tfvars
‚îú‚îÄ‚îÄ staging.tfvars
‚îî‚îÄ‚îÄ prod.tfvars
```

Deploy with: `terraform apply -var-file="environments/prod.tfvars"`

## üö® Troubleshooting

### Common Issues

1. **APIM Deployment Timeout**
   - APIM deployment can take 45+ minutes
   - Check Azure portal for deployment status
   - Ensure subnet has sufficient address space

2. **OpenAI Model Availability**
   - Verify model availability in target region
   - Check Azure OpenAI quotas
   - Ensure proper permissions for model deployment

3. **Private Endpoint Resolution**
   - Verify private DNS zone configuration
   - Check VNet links to DNS zones
   - Ensure NSG rules allow traffic

4. **Authentication Issues**
   - Verify managed identity permissions
   - Check Key Vault access policies
   - Validate RBAC assignments

### Debug Commands

```powershell
# Check Terraform state
terraform state list

# Show specific resource
terraform state show module.apim.azurerm_api_management.main

# Import existing resource (if needed)
terraform import azurerm_resource_group.main /subscriptions/{subscription-id}/resourceGroups/{rg-name}

# Force refresh
terraform refresh
```

## üßπ Cleanup

To destroy all resources:

```powershell
terraform destroy -auto-approve
```

**Warning**: This will permanently delete all resources. Ensure you have backups of any important data.

## üìà Cost Optimization

### Resource Costs (Approximate monthly costs in East US)

| Resource | SKU | Estimated Cost |
|----------|-----|----------------|
| API Management (Developer) | 1 unit | $50 |
| Azure OpenAI (30K TPM) | S0 | $900* |
| Log Analytics (5GB/month) | PerGB2018 | $12 |
| Event Hub (Standard) | 1 TU | $22 |
| VNet & Private Endpoints | Standard | $15 |

*Actual OpenAI costs depend on usage (tokens consumed)

### Cost Optimization Tips

1. **Right-size APIM SKU**: Use Developer for non-prod
2. **Monitor Token Usage**: Set up alerts for high consumption
3. **Log Retention**: Adjust retention periods based on compliance needs
4. **Reserved Capacity**: Consider reserved instances for predictable workloads

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests and documentation
5. Submit a pull request

## üìÑ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

## üîó Additional Resources

- [Azure OpenAI Service Documentation](https://docs.microsoft.com/azure/cognitive-services/openai/)
- [Azure API Management Documentation](https://docs.microsoft.com/azure/api-management/)
- [Terraform Azure Provider](https://registry.terraform.io/providers/hashicorp/azurerm/latest)
- [Azure APIM Policies Reference](https://docs.microsoft.com/azure/api-management/api-management-policies)

---

**Note**: This deployment creates production-ready infrastructure with private endpoints and comprehensive monitoring. Always review security configurations and adjust based on your organization's requirements.